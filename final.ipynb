{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "A toy problem As a dataset, we chose a pretty standard not linearly separable dataset made of two classes \"0\" and \"1\". i use Mean Squared Error (MSE)"
      ],
      "metadata": {
        "id": "4odHIuvAq-an"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cL2Ra9AgrRwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "5MyOFzdtrD6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "i have used a fixed errors in dataset generation and visualization np.random.seed(0) for reproducibility."
      ],
      "metadata": {
        "id": "48hX_od8rPtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset(N_points):\n",
        "\n",
        "    radiuses = np.random.uniform(0, 0.5, size=N_points//2)\n",
        "    angles = np.random.uniform(0, 2*math.pi, size=N_points//2)\n",
        "\n",
        "    x_1 = (radiuses * np.cos(angles)).reshape(N_points//2, 1)\n",
        "    x_2 = (radiuses * np.sin(angles)).reshape(N_points//2, 1)\n",
        "    X_class_1 = np.concatenate((x_1, x_2), axis=1)\n",
        "    Y_class_1 = np.full((N_points//2,), 1)\n",
        "\n",
        "    radiuses = np.random.uniform(0.6, 1, size=N_points//2)\n",
        "    angles = np.random.uniform(0, 2*math.pi, size=N_points//2)\n",
        "\n",
        "    x_1 = (radiuses * np.cos(angles)).reshape(N_points//2, 1)\n",
        "    x_2 = (radiuses * np.sin(angles)).reshape(N_points//2, 1)\n",
        "    X_class_0 = np.concatenate((x_1, x_2), axis=1)\n",
        "    Y_class_0 = np.full((N_points//2,), 0)\n",
        "\n",
        "    X = np.concatenate((X_class_1, X_class_0), axis=0)\n",
        "    Y = np.concatenate((Y_class_1, Y_class_0), axis=0)\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "IRWONft4r9QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forward propagation"
      ],
      "metadata": {
        "id": "4ymTaKkVsGN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_points = 1000\n",
        "X, Y = generate_dataset(N_points)\n",
        "\n",
        "# Plot dataset\n",
        "plt.scatter(X[:N_points//2, 0], X[:N_points//2, 1], color='red', label='Class 1')\n",
        "plt.scatter(X[N_points//2:, 0], X[N_points//2:, 1], color='blue', label='Class 0')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WfPWLE9Xr-CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = {\n",
        "    'W1': np.random.randn(3, 2) * 0.01,\n",
        "    'b1': np.zeros(3),\n",
        "    'W2': np.random.randn(3) * 0.01,\n",
        "    'b2': 0,\n",
        "}"
      ],
      "metadata": {
        "id": "GkrVg4oPsQbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sigmoid betwwen 0 and  1 gives 0.5"
      ],
      "metadata": {
        "id": "tpCs2VVjiVun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "3HWYtj9vguct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, weights):\n",
        "    Z1 = np.dot(X, weights['W1'].T) + weights['b1']\n",
        "    H = sigmoid(Z1)\n",
        "    Z2 = np.dot(H, weights['W2'].T) + weights['b2']\n",
        "    Y_pred = sigmoid(Z2)\n",
        "    return Y_pred, Z2, H, Z1"
      ],
      "metadata": {
        "id": "7qsc7_VTgwoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    # i computed loss using Mean Squared Error"
      ],
      "metadata": {
        "id": "99Voh8poikgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def back_propagation(X, Y_T, weights):\n",
        "    N_points = X.shape[0]\n",
        "    Y_pred, Z2, H, Z1 = forward_propagation(X, weights)\n",
        "\n",
        "\n",
        "    loss = np.mean((Y_pred - Y_T) ** 2)\n",
        "\n",
        "\n",
        "    dLdY = 2 * (Y_pred - Y_T) / N_points\n",
        "    dLdZ2 = dLdY * (sigmoid(Z2) * (1 - sigmoid(Z2)))\n",
        "    dLdW2 = np.dot(H.T, dLdZ2)\n",
        "    dLdb2 = np.sum(dLdZ2)\n",
        "\n",
        "    dLdH = np.dot(dLdZ2.reshape(N_points, 1), weights['W2'].reshape(1, 3))\n",
        "    dLdZ1 = dLdH * (sigmoid(Z1) * (1 - sigmoid(Z1)))\n",
        "    dLdW1 = np.dot(dLdZ1.T, X)\n",
        "    dLdb1 = np.sum(dLdZ1, axis=0)\n",
        "\n",
        "    gradients = {\n",
        "        'W1': dLdW1,\n",
        "        'b1': dLdb1,\n",
        "        'W2': dLdW2,\n",
        "        'b2': dLdb2,\n",
        "    }\n",
        "    return gradients, loss"
      ],
      "metadata": {
        "id": "PYYKjXJ8g2Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2000\n",
        "learning_rate = 0.1\n",
        "initial_weights = copy.deepcopy(weights)"
      ],
      "metadata": {
        "id": "jcB68YrlhAM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "    gradients, loss = back_propagation(X, Y, weights)\n",
        "    for weight_name in weights:\n",
        "        weights[weight_name] -= learning_rate * gradients[weight_name]\n",
        "    losses.append(loss)"
      ],
      "metadata": {
        "id": "s6kiK7UehFyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(epochs), losses)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LSf6SRb9hIav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualization(weights, X_data, title, superposed_training=False):\n",
        "    N_test_points = 1000\n",
        "    xs = np.linspace(1.1*np.min(X_data), 1.1*np.max(X_data), N_test_points)\n",
        "    datapoints = np.transpose([np.tile(xs, len(xs)), np.repeat(xs, len(xs))])\n",
        "    Y_initial = forward_propagation(datapoints, weights)[0].reshape(N_test_points, N_test_points)\n",
        "\n",
        "    X1, X2 = np.meshgrid(xs, xs)\n",
        "    plt.pcolormesh(X1, X2, Y_initial, shading='auto', cmap='coolwarm')\n",
        "    plt.colorbar(label='P(Class 1)')\n",
        "\n",
        "    if superposed_training:\n",
        "        plt.scatter(X_data[:N_points//2, 0], X_data[:N_points//2, 1], color='red')\n",
        "        plt.scatter(X_data[N_points//2:, 0], X_data[N_points//2:, 1], color='blue')\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "pH1cLrRPhLWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "initial_predictions = forward_propagation(X, initial_weights)[0]\n",
        "trained_predictions = forward_propagation(X, weights)[0]"
      ],
      "metadata": {
        "id": "1WqI3R7ehKuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_preds_binary = (initial_predictions >= 0.5).astype(int)\n",
        "trained_preds_binary = (trained_predictions >= 0.5).astype(int)"
      ],
      "metadata": {
        "id": "yZosCjKyhU9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_accuracy = np.mean(initial_preds_binary == Y)\n",
        "trained_accuracy = np.mean(trained_preds_binary == Y)"
      ],
      "metadata": {
        "id": "MmROL1iVhX6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"accuracy before training (Forward Pass Only): {initial_accuracy * 100:.2f}%\")\n",
        "print(f\"accuracy after training (Forward + Backward): {trained_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "0mybAqRChauR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualization(initial_weights, X, \"Before Training (Forward Pass Only)\", True)\n",
        "visualization(weights, X, \"After Training (Forward + Backpropagation)\", True)"
      ],
      "metadata": {
        "id": "0ZUmcMQchcwT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}